if __name__ == "__main__":
    from torch.utils.data import DataLoader
    from torch.optim import AdamW
    from tqdm import tqdm
    from typing import List, Union

    import argparse
    import paintstorch2.data as pt2_data
    import paintstorch2.model as pt2_model
    import torch
    import torch.nn as nn


    def to_cuda(*args: List[Union[nn.Module, torch.Tensor]]) -> None:
        for e in args:
            e.cuda()


    def to_train(*args: List[nn.Module]) -> None:
        for e in args:
            e.train()
            for param in e.parameters():
                param.requires_grad = True


    def to_eval(*args: List[nn.Module]) -> None:
        for e in args:
            e.eval()
            for param in e.parameters():
                param.requires_grad = False


    parser = argparse.ArgumentParser()
    parser.add_argument("--latent_dim", type=int, default=128)
    parser.add_argument("--capacity",   type=int, default=64)
    parser.add_argument("--epochs",     type=int, default=200)
    parser.add_argument("--batch_size", type=int, default=32)
    parser.add_argument("--dataset",    type=str, default="dataset")
    args = parser.parse_args()

    Î± = 1e-4        # AdamW Learning Rate
    Î² = 0.5, 0.9    # AdamW Betas
    Îµ_drift = 1e-3  # Discriminator Drifiting
    Î»1 = 1e-4       # Adversarial Loss Weight
    Î»2 = 10         # Gradient Penalty Weight

    dataset = pt2_data.ModularPaintsTorch2Dataset(pt2_data.Modules(
        color=pt2_data.kMeansColorSimplifier((5, 15)),
        hints=pt2_data.RandomHintsGenerator(),
        lineart=pt2_data.xDoGLineartGenerator(),
        mask=pt2_data.kMeansMaskGenerator((2, 10)),
    ), args.dataset, False)

    n = 2
    loader = DataLoader(dataset, args.batch_size, shuffle=False, num_workers=n)

    F1 = torch.jit.load(pt2_model.ILLUSTRATION2VEC)
    F2 = torch.jit.load(pt2_model.VGG16)
    
    S = pt2_model.Embedding(args.latent_dim)
    G = pt2_model.Generator(args.latent_dim, args.capacity)
    D = pt2_model.Discriminator(args.capacity)

    GP = pt2_model.GradientPenalty(D, Î»2)
    MSE = nn.MSELoss()

    to_cuda(F1, F2, S, G, D, GP, MSE)
    to_eval(F1, F2)

    GS_parameters = list(G.parameters()) + list(S.parameters())
    optim_GS = AdamW(GS_parameters, lr=Î±, betas=Î²)
    optim_D = AdamW(D.parameters(), lr=Î±, betas=Î²)

    for epoch in tqdm(range(args.epochs), desc="Epoch"):
        total_ğ“›_D = 0
        total_ğ“›_G = 0

        pbar = tqdm(loader, desc="Batch")
        for i, batch in enumerate(pbar):
            artist_id, composition, hints, style, illustration = batch
            b, c, h, w = composition.size()

            artist_id = artist_id.cuda()
            composition = composition.cuda()
            hints = hints.cuda()
            style = style.cuda()
            illustration = illustration.cuda()
            noise = torch.rand((b, 1, h, w)).cuda()

            # =============
            # DISCRIMINATOR
            # =============
            pbar.set_description("Batch Discriminator")

            to_train(D)
            to_eval(S, G)
            optim_GS.zero_grad()
            optim_D.zero_grad()

            with torch.no_grad():
                features = F1(composition[:, :3])
                style_embedding = S(style)
                
                fake = G(composition, hints, features, style_embedding, noise)
                fake = composition[:, :3] + fake * composition[:, :-1]
            
            ğ“›_fake = D(fake, features).mean(0).view(1)
            ğ“›_real = D(illustration, features).mean(0).view(1)
            ğ“›_critic = ğ“›_fake - ğ“›_real
            ğ“›_p = GP(illustration, fake, features) + Îµ_drift * (ğ“›_real ** 2)

            ğ“›_D = ğ“›_critic + ğ“›_p
            ğ“›_D.backward()

            optim_D.step()
            total_ğ“›_D += ğ“›_D.item() / len(loader)

            # =========
            # GENERATOR
            # =========
            pbar.set_description("Batch Generator")

            to_train(S, G)
            to_eval(D)
            optim_GS.zero_grad()
            optim_D.zero_grad()

            with torch.no_grad():
                features = F1(composition[:, :3])
            
            style_embedding = S(style)
            fake = G(composition, hints, features, style_embedding, noise)
            fake = composition[:, :3] + fake * composition[:, :-1]

            features1 = F2(fake)
            with torch.no_grad():
                features2 = F2(illustration)

            ğ“›_adv = - D(fake, features).mean()
            ğ“›_content = MSE(features1, features2)

            ğ“›_G = ğ“›_content + Î»1 * ğ“›_adv
            ğ“›_G.backward()

            optim_GS.step()
            total_ğ“›_G += ğ“›_G.item() / len(loader)

            # =======
            # LOGGING
            # =======
            pbar.set_postfix(ğ“›_D=total_ğ“›_D, ğ“›_G=total_ğ“›_G)

        torch.save({
            "args": vars(args),
            "S": S.state_dict(),
            "G": G.state_dict(),
            "D": D.state_dict(),
        }, f"paintstorch2_{epoch:0{len(str(args.epochs))}d}.pth")