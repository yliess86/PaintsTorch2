if __name__ == "__main__":
    from torch.utils.data import DataLoader
    from torch.optim import AdamW
    from torch.utils.tensorboard import SummaryWriter
    from tqdm import tqdm
    from typing import List, Union

    import argparse
    import multiprocessing
    import os
    import paintstorch2.data as pt2_data
    import paintstorch2.model as pt2_model
    import torch
    import torch.nn as nn


    def to_cuda(*args: List[Union[nn.Module, torch.Tensor]]) -> None:
        for e in args:
            e.cuda()


    def to_train(*args: List[nn.Module]) -> None:
        for e in args:
            e.train()
            for param in e.parameters():
                param.requires_grad = True


    def to_eval(*args: List[nn.Module]) -> None:
        for e in args:
            e.eval()
            for param in e.parameters():
                param.requires_grad = False


    parser = argparse.ArgumentParser()
    parser.add_argument("--latent_dim",   type=int, default=128)
    parser.add_argument("--capacity",     type=int, default=64)
    parser.add_argument("--epochs",       type=int, default=200)
    parser.add_argument("--batch_size",   type=int, default=32)
    parser.add_argument("--dataset",      type=str, default="dataset")
    parser.add_argument("--checkpoints",  type=str, default="checkpoints")
    parser.add_argument("--tensorboards", type=str, default="tensorboards")
    args = parser.parse_args()

    if not os.path.exists(args.checkpoints):
        os.makedirs(args.checkpoints, exist_ok=True)
    if not os.path.exists(args.tensorboards):
        os.makedirs(args.tensorboards, exist_ok=True)

    # =====
    # SETUP
    # =====
    writer = SummaryWriter(log_dir=args.tensorboards)

    Î± = 1e-4        # AdamW Learning Rate
    Î² = 0.5, 0.9    # AdamW Betas
    Îµ_drift = 1e-3  # Discriminator Drifiting
    Î»1 = 1e-4       # Adversarial Loss Weight
    Î»2 = 10         # Gradient Penalty Weight

    dataset = pt2_data.ModularPaintsTorch2Dataset(pt2_data.Modules(
        color=pt2_data.kMeansColorSimplifier((5, 10)),
        hints=pt2_data.RandomHintsGenerator(),
        lineart=pt2_data.xDoGLineartGenerator(),
        mask=pt2_data.kMeansMaskGenerator((2, 5)),
    ), args.dataset, False)

    loader = DataLoader(
        dataset,
        args.batch_size,
        shuffle=False,
        num_workers=multiprocessing.cpu_count(),
    )

    F1 = torch.jit.load(pt2_model.ILLUSTRATION2VEC)
    F2 = torch.jit.load(pt2_model.VGG16)
    
    S = pt2_model.Embedding(args.latent_dim)
    G = pt2_model.Generator(args.latent_dim, args.capacity)
    D = pt2_model.Discriminator(args.capacity)

    GP = pt2_model.GradientPenalty(D, Î»2)
    MSE = nn.MSELoss()

    to_cuda(F1, F2, S, G, D, GP, MSE)
    to_eval(F1, F2)

    GS_parameters = list(G.parameters()) + list(S.parameters())
    optim_GS = AdamW(GS_parameters, lr=Î±, betas=Î²)
    optim_D = AdamW(D.parameters(), lr=Î±, betas=Î²)

    # ===============
    # VALIDATION DATA
    # ===============
    _, v_composition, v_hints, v_style, v_illustration = dataset[7]
    c, h, w = v_composition.size()

    v_composition = v_composition.unsqueeze(0).cuda()
    v_hints = v_hints.unsqueeze(0).cuda()
    v_style = v_style.unsqueeze(0).cuda()
    v_illustration = v_illustration.unsqueeze(0).cuda()
    v_noise = torch.rand((1, 1, h, w)).cuda()

    with torch.no_grad():
        v_features = F1(v_composition[:, :3])
    
    # ========
    # TRAINING
    # ========
    for epoch in tqdm(range(args.epochs), desc="Epoch"):
        total_ğ“›_D = 0
        total_ğ“›_G = 0

        pbar = tqdm(loader, desc="Batch")
        for i, batch in enumerate(pbar):
            artist_id, composition, hints, style, illustration = batch
            b, c, h, w = composition.size()

            artist_id = artist_id.cuda()
            composition = composition.cuda()
            hints = hints.cuda()
            style = style.cuda()
            illustration = illustration.cuda()
            noise = torch.rand((b, 1, h, w)).cuda()

            # ======
            # COMMON
            # ======
            to_train(D, S, G)
            optim_GS.zero_grad()
            optim_D.zero_grad()

            with torch.no_grad():
                features = F1(composition[:, :3])
            
            style_embedding = S(style)
            fake = G(composition, hints, features, style_embedding, noise)
            fake = composition[:, :3] + fake * composition[:, :-1]
            
            # =============
            # DISCRIMINATOR
            # =============
            pbar.set_description("Batch Discriminator")
            
            d_fake = fake.detach()
            
            ğ“›_fake = torch.relu(1 + D(d_fake, features).mean(0).view(1))
            ğ“›_fake.backward(retain_graph=True)

            ğ“›_real = torch.relu(1 - D(illustration, features).mean(0).view(1))
            ğ“›_real_drift = -ğ“›_real + Îµ_drift * (ğ“›_real ** 2)
            ğ“›_real_drift.backward(retain_graph=True)

            ğ“›_p = GP(illustration, d_fake, features)
            ğ“›_p.backward()

            ğ“›_D = ğ“›_fake + ğ“›_real_drift + ğ“›_p
            optim_D.step()
            total_ğ“›_D += ğ“›_D.item() / len(loader)

            # =========
            # GENERATOR
            # =========
            pbar.set_description("Batch Generator")

            to_eval(D)
            optim_D.zero_grad()
            
            ğ“›_adv = -Î»1 * D(fake, features).mean()
            ğ“›_adv.backward(retain_graph=True)

            features1 = F2(fake)
            with torch.no_grad():
                features2 = F2(illustration)

            ğ“›_content = MSE(features1, features2)
            ğ“›_content.backward()

            ğ“›_G = ğ“›_content + ğ“›_adv
            optim_GS.step()
            total_ğ“›_G += ğ“›_G.item() / len(loader)

            # =============
            # BATCH LOGGING
            # =============
            pbar.set_postfix(ğ“›_D=total_ğ“›_D, ğ“›_G=total_ğ“›_G)

        # =============
        # EPOCH LOGGING
        # =============
        writer.add_scalar("ğ“›_D", total_ğ“›_D, epoch)
        writer.add_scalar("ğ“›_G", total_ğ“›_G, epoch)

        to_eval(S, G, D)

        with torch.no_grad():
            fake = v_composition[:, :3] + G(
                v_composition,
                v_hints,
                v_features,
                S(v_style),
                v_noise,
            ) * v_composition[:, :-1]

        composition = v_composition.squeeze(0).cpu()
        hints = v_hints.squeeze(0).cpu()
        style = v_style.squeeze(0).cpu()
        illustration = v_illustration.squeeze(0).cpu()
        fake = fake.squeeze(0).cpu()

        writer.add_image("composition/color", composition[:3], epoch)
        writer.add_image("composition/mask", composition[None, -1], epoch)
        writer.add_image("hints/color", hints[:3], epoch)
        writer.add_image("hints/mask", hints[None, -1], epoch)
        writer.add_image("style", style, epoch)
        writer.add_image("illustration", illustration, epoch)

        torch.save({
            "args": vars(args),
            "S": S.state_dict(),
            "G": G.state_dict(),
            "D": D.state_dict(),
        }, os.path.join(
            args.checkpoints,
            f"paintstorch2_{epoch:0{len(str(args.epochs))}d}.pth",
        ))